# 概要

アニメキャラクターをAIに判別させて遊ぶことができます。

[ホームページへ](https://zwanywhere.com/)
# 使用技術
以下のリンクから確認できます。  
[StackShare](https://stackshare.io/zawa/my-portfolio)

キャラクター判別モデルの作成とユーザーが入力した画像データの処理の説明は[こちらのリポジトリ](https://github.com/zoniha/create-anime-detection-dataset)にファイルと説明があります。
# 作成に関して

今回のWebアプリは大学時代に研究していた深層学習の画像認識分野を取り入れ、誰でも手軽にAIを体験できるものにしました。キャラクター認識モデルの作成はデータセットの作成からすべて自分でプログラムを書いて実装しました。

作成中に苦労したのは、JPGやPNGなどの画像データを入力データとする画像認識モデルに対し、ユーザーから入力された画像データはバイナリデータとして扱われるということでした。バイナリデータから画像データへの変換はBytesIOを使用することで解決しましたが、その過程でPillowを使用しなければならず、Pillowは次の工程で使用するOpenCVと画像データの配列の扱い方が異なるため、PillowからOpenCVへの画像の受け渡しを注意して行わなければなりませんでした。認識モデルは画像の配列データをもとに判別を行うため、画像データの受け渡しの際にRGBの順番や上下が逆になってしまうとモデルが認識を誤ってしまいます。そのため、私はJupyter Lab上でデータの受け渡しの度に画像を描写し、確認することでユーザーから入力された画像を適切にモデルへと入力できるようにしました。
